{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ High-Architecture ASR Training - Google Colab\n",
    "\n",
    "**Auto-configured ASR training with zero manual tuning!**\n",
    "\n",
    "This notebook uses intelligent configuration to automatically optimize all training settings based on your GPU.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö° Quick Start\n",
    "\n",
    "1. **Runtime ‚Üí Change runtime type ‚Üí GPU (T4, L4, or A100)**\n",
    "2. **Run all cells** (Runtime ‚Üí Run all)\n",
    "3. **Enter your HuggingFace token when prompted**\n",
    "\n",
    "That's it! The system will auto-configure everything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Clone Repository & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/NursultanMRX/asr-training-system.git\n",
    "%cd asr-training-system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "print(\"‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîë Step 2: HuggingFace Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Option 1: Interactive login (recommended)\n",
    "login()\n",
    "\n",
    "# Option 2: Direct token (uncomment and add your token)\n",
    "# login(token=\"hf_YOUR_TOKEN_HERE\")\n",
    "\n",
    "print(\"‚úÖ Logged in to HuggingFace!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üñ•Ô∏è Step 3: Check Available Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import psutil\n",
    "\n",
    "print(\"System Information:\")\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: No GPU detected! Training will be very slow.\")\n",
    "    print(\"Go to Runtime ‚Üí Change runtime type ‚Üí Select GPU\")\n",
    "\n",
    "print(f\"\\nCPU RAM: {psutil.virtual_memory().total / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Step 4: Configure Training (Optional)\n",
    "\n",
    "Edit these settings if needed, or leave defaults for auto-configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Configuration (will be auto-optimized)\n",
    "DATASET_REPO_ID = \"nickoo004/karakalpak-speech-60h-production-v2\"\n",
    "BASE_MODEL = \"facebook/wav2vec2-xls-r-1b\"\n",
    "MODEL_NAME = \"wav2vec2-xls-r-1b-karakalpak-colab\"\n",
    "HF_USERNAME = \"nickoo004\"  # Change to your username\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "TARGET_BATCH_SIZE = 32\n",
    "LEARNING_RATE = 3e-4\n",
    "SAFETY_MARGIN = 0.85  # Use 85% of available memory\n",
    "\n",
    "print(\"Configuration set!\")\n",
    "print(f\"Dataset: {DATASET_REPO_ID}\")\n",
    "print(f\"Model: {BASE_MODEL}\")\n",
    "print(f\"Output: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 5: Run Training with Auto-Configuration\n",
    "\n",
    "This cell will:\n",
    "1. Analyze your GPU and dataset\n",
    "2. Auto-configure optimal settings\n",
    "3. Train the model\n",
    "4. Push to HuggingFace Hub\n",
    "\n",
    "**Note:** This may take several hours depending on your GPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the training script\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "# Run training\n",
    "!python src/optimized_training.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 6: Monitor Training (Optional)\n",
    "\n",
    "While training runs, you can monitor progress with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir outputs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Step 7: Download Results (Optional)\n",
    "\n",
    "Download your trained model and configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "# Create zip of outputs\n",
    "!zip -r training_results.zip outputs/ configs/ training_config.json\n",
    "\n",
    "# Download\n",
    "files.download('training_results.zip')\n",
    "\n",
    "print(\"‚úÖ Results downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 8: View Configuration\n",
    "\n",
    "See what settings were auto-configured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load and display the auto-generated config\n",
    "with open('training_config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(\"Auto-Configured Settings:\")\n",
    "print(\"=\"*50)\n",
    "for key, value in config.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Notes\n",
    "\n",
    "### Colab-Specific Tips:\n",
    "\n",
    "1. **GPU Selection:**\n",
    "   - T4 (Free): Works with XLS-R-300M, may struggle with XLS-R-1B\n",
    "   - L4 (Colab Pro): Great for XLS-R-1B\n",
    "   - A100 (Colab Pro+): Best performance\n",
    "\n",
    "2. **Session Timeout:**\n",
    "   - Keep browser tab open\n",
    "   - Run small script to prevent disconnect:\n",
    "   ```javascript\n",
    "   function ClickConnect(){\n",
    "       console.log(\"Working\");\n",
    "       document.querySelector(\"colab-connect-button\").click()\n",
    "   }\n",
    "   setInterval(ClickConnect, 60000)\n",
    "   ```\n",
    "\n",
    "3. **Checkpointing:**\n",
    "   - Model saves to `outputs/` every N steps\n",
    "   - Auto-pushed to HuggingFace Hub (if configured)\n",
    "   - Download checkpoints before session ends\n",
    "\n",
    "4. **Memory Issues:**\n",
    "   - System will auto-reduce batch size if OOM\n",
    "   - Or adjust `SAFETY_MARGIN` to 0.70 (more conservative)\n",
    "\n",
    "### Expected Training Times:\n",
    "\n",
    "| GPU | Model | Dataset | Time |\n",
    "|-----|-------|---------|------|\n",
    "| T4 | XLS-R-300M | 60h | ~24-36h |\n",
    "| L4 | XLS-R-1B | 60h | ~12-18h |\n",
    "| A100 | XLS-R-1B | 60h | ~6-8h |\n",
    "\n",
    "---\n",
    "\n",
    "**Made with ‚ù§Ô∏è for the ASR community**\n",
    "\n",
    "Repository: https://github.com/NursultanMRX/asr-training-system"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
